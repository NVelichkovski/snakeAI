{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NonConvolutional.ipynb","provenance":[],"mount_file_id":"1r-ofBNYw3nkELVBV6NY_suAp2p2aYr-L","authorship_tag":"ABX9TyP7PmvknxYL/qQLOqoV6TXJ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"IBvFxK14L5II","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593435912296,"user_tz":-120,"elapsed":745,"user":{"displayName":"nikola velickovski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzeg18nucXBD-pvS7oJM0Vi_lAfUMShS3mp5rLDw=s64","userId":"03513249108961782086"}}},"source":["import sys\n","sys.path.append(\"/content/drive/My Drive/snakeAI\")\n","\n","import tensorflow as tf\n","import tensorflow.keras as k\n","\n","from Snake.environment import SnakeMaze\n","\n","from Snake.utils import resize_image, save_images, save_video, save_graph, save_eval, generate_animation, euclidean_distance\n","from Snake.variables import Cell, Status\n","\n","import matplotlib.pyplot as plt\n","\n","import numpy as np\n","import os\n","\n","from models.replay_memory import ReplayMemory, Experience\n","from time import time\n","from datetime import datetime\n","from Snake.agent import Snake\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"-eXebng9EiTs","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593435912299,"user_tz":-120,"elapsed":618,"user":{"displayName":"nikola velickovski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzeg18nucXBD-pvS7oJM0Vi_lAfUMShS3mp5rLDw=s64","userId":"03513249108961782086"}}},"source":["def get_observation(env, handle=0, local_knowledge=5):\n","  snake = env.snakes[handle]\n","\n","  if snake.status == Status.DEAD:\n","    return np.zeros((33 + local_knowledge**2 ))\n","\n","  snake_position = snake.body[0]\n","\n","  env_width, env_height, = env.matrix.shape\n","\n","  directions_offsets = [(0, 1), (-1, 0), (1, 0), (0, -1), (-1, 1), (1, -1), (1, 1), (-1, -1)]\n","  features = []\n","\n","  for offset_x, offset_y in directions_offsets: \n","    distances_to_cell_type = {c: -1 for c in Cell.CELL_DICT.values()}\n","    tmp_x, tmp_y = snake_position\n","    tmp_x += offset_x\n","    tmp_y += offset_y\n","    \n","    distance = 1\n","    while (-1 < tmp_x < env_height) and (-1 < tmp_y < env_width):\n","      curr_cell_type = env.matrix[tmp_x, tmp_y]\n","      if distances_to_cell_type[curr_cell_type] == -1:\n","        distances_to_cell_type[curr_cell_type] = distance\n","      distance += 1\n","      tmp_x += offset_x\n","      tmp_y += offset_y\n","\n","    del distances_to_cell_type[Cell.EMPTY_CELL]\n","    features.extend(distances_to_cell_type.values())\n","  \n","  features.append(len(snake.body))\n","\n","  tmp_matrix = np.pad(env.matrix, local_knowledge)\n","  tmp_matrix = tmp_matrix[\n","                          snake_position[0]: snake_position[0]+local_knowledge, \n","                          snake_position[1]: snake_position[1]+local_knowledge, \n","                          ]\n","  features.extend(tmp_matrix.flatten())\n","  \n","  return np.array(features)  \n","\n","def reward(snake: Snake, env: SnakeMaze, direction):\n","    if snake.status == Status.DEAD:\n","        return -500\n","    else:\n","        r = 0\n","        r += snake.steps_without_food * (-2)\n","        r += 350 if snake.steps_without_food == 1 else 0\n","        return r\n","\n","@tf.function\n","def loss(p, t):\n","    return tf.reduce_sum(tf.square(t - p))\n","\n","\n","@tf.function\n","def train_step(states, targets, model, optimizer):\n","    with tf.GradientTape() as tape:\n","        q = model(states, training=True)\n","        _loss = loss(q, targets)\n","    grad = tape.gradient(_loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(grad, model.trainable_variables))"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"ww0qLBExK9Fw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593435913272,"user_tz":-120,"elapsed":1036,"user":{"displayName":"nikola velickovski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzeg18nucXBD-pvS7oJM0Vi_lAfUMShS3mp5rLDw=s64","userId":"03513249108961782086"}}},"source":["NUM_NOT_TRAINABLE_BLOCKS = 4\n","\n","IMAGE_SIZE = (64, 64)\n","IMAGE_SHAPE = (*IMAGE_SIZE, 3)\n","\n","learning_rate = 1e-5\n","\n","config = {\n","  \"max_steps_per_episode\": 500,\n","  \"num_rolling_avg_sample\": 10,\n","  \"evaluate_each\": 100,\n","  \"save_models\": True,\n","  \"save_graphs\": True,\n","  \"gamma\": .9,\n","  \"epsilon\": 1,\n","  \"epsilon_decay\": 0.00005,\n","  \"boundaries\": True,\n","  \"maze_width\": 10,\n","  \"image_size\": IMAGE_SIZE,\n","  \"batch_size\": 128,\n","  \"path_to_weights\": os.path.join(*['drive', 'My Drive', 'snakeAI', 'trainings', 'NonConvolutional', '28Jun2020__201526222058', 'model']),\n","  \"comment\": f\"\"\"\n","  Architecture: Non-convolutional (continuing from 28Jun2020__201526222058)\n","  Optimizer: Adam ( with amsgrad )\n","  Hyperparameters:\n","    lr = {learning_rate}\n","  Reward:\n","    if snake.status == Status.DEAD:\n","        return -500\n","    else:\n","        r = 0\n","        r += snake.steps_without_food * (-2)\n","        r += 350 if snake.steps_without_food == 1 else 0\n","        return r\n","  \"\"\"\n","}"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"s62GEfXROQ6f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1593436777606,"user_tz":-120,"elapsed":600,"user":{"displayName":"nikola velickovski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzeg18nucXBD-pvS7oJM0Vi_lAfUMShS3mp5rLDw=s64","userId":"03513249108961782086"}},"outputId":"c3ba177c-f529-4e07-da04-5127d14cc00f"},"source":["np.array([1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]).reshape(-1, 3)"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1, 2, 3],\n","       [1, 2, 3],\n","       [1, 2, 3],\n","       [1, 2, 3],\n","       [1, 2, 3]])"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"8QPINLD9NDUW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1rTLjHZ0SxwM7qPDkcaGO3Esz50s0ftcg"},"executionInfo":{"status":"error","timestamp":1593436541900,"user_tz":-120,"elapsed":627487,"user":{"displayName":"nikola velickovski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzeg18nucXBD-pvS7oJM0Vi_lAfUMShS3mp5rLDw=s64","userId":"03513249108961782086"}},"outputId":"3fa882ba-e870-40fd-fce2-504891f17634"},"source":["model = k.Sequential([\n","                      k.layers.Input(58, name='InputLayer'),\n","                      k.layers.Dense(40, activation='relu', kernel_regularizer=k.regularizers.l1_l2(), name='FirstDense'),\n","                      k.layers.Dropout(.5, name='FirstDropout'),\n","                      k.layers.Dense(20, activation='relu', kernel_regularizer=k.regularizers.l1_l2(), name='SecondDense'),\n","                      k.layers.Dropout(.5, name='SecondDropout'),\n","                      k.layers.Dense(4, activation='softmax', kernel_regularizer=k.regularizers.l1_l2(), name='ThirdDense'),\n","], name='NonSequential')\n","optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, amsgrad=True)\n","config['training_dir'] = os.path.join(*['drive', 'My Drive', 'snakeAI', 'trainings', \"NonConvolutional\", datetime.now().strftime('%d%h%Y__%H%M%S%f')])\n","\n","verbose = config['verbose'] if 'verbose' in config else True\n","save_videos_ = config['save_videos'] if 'save_videos' in config else False\n","save_images_ = config['save_images'] if 'save_images' in config else False\n","evaluate_each = config['evaluate_each'] if 'evaluate_each' in config else 50\n","num_rolling_avg_sample = config['num_rolling_avg_sample'] if 'num_rolling_avg_sample' in config else 50\n","max_steps_per_episode = config['max_steps_per_episode'] if 'max_steps_per_episode' in config else 200\n","num_episodes = config['num_episodes'] if 'num_episodes' in config else None\n","gamma = config['gamma'] if 'gamma' in config else .8\n","epsilon = config['epsilon'] if 'epsilon' in config else 1.\n","epsilon_decay = config['epsilon_decay'] if 'epsilon_decay' in config else 5e-4\n","min_epsilon = config['min_epsilon'] if 'min_epsilon' in config else 1e-2\n","memory_size = config['memory_size'] if 'memory_size' in config else 10000\n","boundaries = config['boundaries'] if 'boundaries' in config else True\n","maze_width = config['maze_width'] if 'maze_width' in config else 10\n","maze_height = config['maze_height'] if 'maze_height' in config else maze_width\n","max_snakes = config['max_snakes'] if 'max_snakes' in config else 1\n","path_to_weights = config['path_to_weights'] if 'path_to_weights' in config else None\n","image_size = config['image_size'] if 'image_size' in config else (112, 112)\n","training_dir = config['training_dir'] if 'training_dir' in config else './'\n","comment = config['comment'] if 'comment' in config else ''\n","batch_size = config['batch_size'] if 'batch_size' in config else 64\n","comment = comment + f\"\"\"\n","\n","    _________________________________________________________\n","    ---------------------------------------------------------\n","\n","    max_steps_per_episode  --> {max_steps_per_episode}\n","    num_episodes           --> {num_episodes}\n","    gamma                  --> {gamma}\n","    epsilon                --> {epsilon}\n","    epsilon_decay          --> {epsilon_decay}\n","    min_epsilon            --> {min_epsilon}\n","    memory_size            --> {memory_size}\n","    boundaries             --> {boundaries}\n","    maze_width             --> {maze_width}\n","    maze_height            --> {maze_height}\n","    max_snakes             --> {max_snakes}\n","    path_to_weights        --> {path_to_weights}\n","    _________________________________________________________\n","    ---------------------------------------------------------\n","    \n","    \"\"\"\n","\n","os.makedirs(training_dir, exist_ok=True)\n","comment_path = os.path.join(training_dir, \"info.txt\")\n","with open(comment_path, \"w\") as text_file:\n","    text_file.write(comment)\n","    model.summary(print_fn=lambda x: text_file.write(x + '\\n'))\n","model.summary()\n","\n","if path_to_weights is not None:\n","    model.load_weights(path_to_weights)\n","\n","episode_number = 0\n","\n","rolling_avg_reward = np.array([])\n","rolling_avg_epsilon = np.array([])\n","\n","\n","reward_window = np.array([])\n","\n","memory = ReplayMemory(capacity=memory_size) if (memory_size > 50 and memory_size > batch_size) else None\n","\n","while num_episodes is None or episode_number < num_episodes:\n","    if verbose:\n","        print(\"____________________________________________________________________________________________\")\n","    is_eval_episode = (episode_number % evaluate_each == 0) or (num_episodes and episode_number == num_episodes - 1)\n","\n","    episode_images = []\n","    is_random_action = []\n","\n","    env = SnakeMaze(\n","        width=maze_width,\n","        height=(maze_height if maze_height is not None else maze_width),\n","        max_num_agents=max_snakes,\n","        with_boundaries=boundaries)\n","    env.reset()\n","\n","    episode_reward = 0\n","\n","    for _ in range(max_steps_per_episode):\n","\n","        if env.num_active_agents == 0:\n","            break\n","\n","        if is_eval_episode and (save_images_ or save_videos_):\n","            episode_images.append(resize_image(env.snake_matrices[0], image_size))\n","            \n","        state = get_observation(env,)\n","        q = model(state.reshape(1, -1))\n","        direction = np.random.randint(4) if np.random.rand() < epsilon else np.argmax(q)\n","        env.step({0: direction})\n","        current_reward = reward(env.snakes[0], env, direction)\n","        state2 = get_observation(env)\n","\n","        episode_reward += current_reward\n","\n","        if reward_window is None:\n","            reward_window = np.array([current_reward])\n","        else:\n","            reward_window = np.append(reward_window, current_reward)\n","\n","        if memory is not None:\n","            memory.push(Experience(state, direction, state2, current_reward))\n","\n","            if np.random.rand() > memory.space():\n","                continue\n","            batches_info = memory.pop()\n","        else:\n","            batches_info = [Experience(state, direction, state2, current_reward)]\n","\n","        states, q_targets = [], []\n","        for state, direction, state2, current_reward in batches_info:\n","            q_target = model(state2.reshape(1, -1))\n","            max_q = np.max(np.max(q_target))\n","            q_target = q_target.numpy()\n","            q_target[0, direction] = current_reward + gamma * max_q\n","\n","            states.append(state)\n","            q_targets.append(q_target)\n","        train_step(np.array(states), np.array(q_targets), model, optimizer)\n","\n","    if verbose:\n","        print(f\"Episode {episode_number + 1} Done!\")\n","        print(f\"Episode reward: {episode_reward}\")\n","        print(f\"Epsilon: {epsilon}\")\n","        if memory is not None:\n","            print(f\"Replay Memory size: {len(memory.experiences)}\")\n","\n","    if len(reward_window) >= num_rolling_avg_sample:\n","        rolling_avg = np.mean(reward_window)\n","        reward_window = np.delete(reward_window, 0)\n","        rolling_avg_reward = np.append(rolling_avg_reward, rolling_avg)\n","        rolling_avg_epsilon = np.append(rolling_avg_epsilon, epsilon)\n","\n","\n","    epsilon = max(epsilon - epsilon_decay, min_epsilon)\n","\n","    if verbose:\n","        print()\n","\n","    if is_eval_episode:\n","        save_eval(model, episode_number, episode_images, rolling_avg_reward, rolling_avg_epsilon, **config)\n","\n","    episode_number += 1"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"R6IvuoTeLoBY","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}